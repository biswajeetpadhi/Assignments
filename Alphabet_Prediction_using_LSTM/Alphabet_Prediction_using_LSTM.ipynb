{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzOs2divDhH9",
    "outputId": "4f078e82-3541-46f8-decd-4d3e0a746862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 4s - loss: 3.2721 - accuracy: 0.0000e+00\n",
      "25/25 - 0s - loss: 3.2507 - accuracy: 0.1200\n",
      "25/25 - 0s - loss: 3.2381 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 3.2243 - accuracy: 0.1200\n",
      "25/25 - 0s - loss: 3.2077 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 3.1861 - accuracy: 0.1200\n",
      "25/25 - 0s - loss: 3.1566 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 3.1180 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 3.0751 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 3.0355 - accuracy: 0.1200\n",
      "25/25 - 0s - loss: 3.0026 - accuracy: 0.1200\n",
      "25/25 - 0s - loss: 2.9778 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 2.9625 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 2.9570 - accuracy: 0.0800\n",
      "25/25 - 0s - loss: 2.9474 - accuracy: 0.1600\n",
      "25/25 - 0s - loss: 2.9101 - accuracy: 0.1600\n",
      "25/25 - 0s - loss: 2.8546 - accuracy: 0.1600\n",
      "25/25 - 0s - loss: 2.7959 - accuracy: 0.2400\n",
      "25/25 - 0s - loss: 2.7317 - accuracy: 0.2000\n",
      "25/25 - 0s - loss: 2.6693 - accuracy: 0.2400\n",
      "25/25 - 0s - loss: 2.6054 - accuracy: 0.2400\n",
      "25/25 - 0s - loss: 2.5482 - accuracy: 0.2400\n",
      "25/25 - 0s - loss: 2.4865 - accuracy: 0.2800\n",
      "25/25 - 0s - loss: 2.4254 - accuracy: 0.3200\n",
      "25/25 - 0s - loss: 2.3603 - accuracy: 0.3200\n",
      "25/25 - 0s - loss: 2.3025 - accuracy: 0.3600\n",
      "25/25 - 0s - loss: 2.2549 - accuracy: 0.2400\n",
      "25/25 - 0s - loss: 2.2078 - accuracy: 0.2800\n",
      "25/25 - 0s - loss: 2.1676 - accuracy: 0.3200\n",
      "25/25 - 0s - loss: 2.1218 - accuracy: 0.3200\n",
      "25/25 - 0s - loss: 2.0851 - accuracy: 0.3200\n",
      "25/25 - 0s - loss: 2.0405 - accuracy: 0.3200\n",
      "25/25 - 0s - loss: 2.0150 - accuracy: 0.3600\n",
      "25/25 - 0s - loss: 1.9645 - accuracy: 0.3600\n",
      "25/25 - 0s - loss: 1.9572 - accuracy: 0.4000\n",
      "25/25 - 0s - loss: 1.8896 - accuracy: 0.5600\n",
      "25/25 - 0s - loss: 1.9145 - accuracy: 0.3200\n",
      "25/25 - 0s - loss: 1.8243 - accuracy: 0.5200\n",
      "25/25 - 0s - loss: 1.8690 - accuracy: 0.3600\n",
      "25/25 - 0s - loss: 1.7678 - accuracy: 0.6000\n",
      "25/25 - 0s - loss: 1.7802 - accuracy: 0.4400\n",
      "25/25 - 0s - loss: 1.7244 - accuracy: 0.5200\n",
      "25/25 - 0s - loss: 1.6957 - accuracy: 0.5600\n",
      "25/25 - 0s - loss: 1.7003 - accuracy: 0.4800\n",
      "25/25 - 0s - loss: 1.6415 - accuracy: 0.6400\n",
      "25/25 - 0s - loss: 1.6617 - accuracy: 0.4800\n",
      "25/25 - 0s - loss: 1.6028 - accuracy: 0.6400\n",
      "25/25 - 0s - loss: 1.5985 - accuracy: 0.5200\n",
      "25/25 - 0s - loss: 1.5718 - accuracy: 0.6400\n",
      "25/25 - 0s - loss: 1.5458 - accuracy: 0.6800\n",
      "25/25 - 0s - loss: 1.5430 - accuracy: 0.5600\n",
      "25/25 - 0s - loss: 1.5060 - accuracy: 0.7200\n",
      "25/25 - 0s - loss: 1.5020 - accuracy: 0.6000\n",
      "25/25 - 0s - loss: 1.4715 - accuracy: 0.7200\n",
      "25/25 - 0s - loss: 1.4581 - accuracy: 0.7200\n",
      "25/25 - 0s - loss: 1.4395 - accuracy: 0.7200\n",
      "25/25 - 0s - loss: 1.4189 - accuracy: 0.7200\n",
      "25/25 - 0s - loss: 1.4055 - accuracy: 0.7200\n",
      "25/25 - 0s - loss: 1.3839 - accuracy: 0.7200\n",
      "25/25 - 0s - loss: 1.3697 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.3513 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.3351 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.3189 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.3017 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.2856 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.2689 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.2528 - accuracy: 0.7600\n",
      "25/25 - 0s - loss: 1.2370 - accuracy: 0.8000\n",
      "25/25 - 0s - loss: 1.2215 - accuracy: 0.8000\n",
      "25/25 - 0s - loss: 1.2063 - accuracy: 0.8400\n",
      "25/25 - 0s - loss: 1.1912 - accuracy: 0.8400\n",
      "25/25 - 0s - loss: 1.1764 - accuracy: 0.8400\n",
      "25/25 - 0s - loss: 1.1618 - accuracy: 0.8800\n",
      "25/25 - 0s - loss: 1.1475 - accuracy: 0.8800\n",
      "25/25 - 0s - loss: 1.1335 - accuracy: 0.8800\n",
      "25/25 - 0s - loss: 1.1197 - accuracy: 0.8800\n",
      "25/25 - 0s - loss: 1.1061 - accuracy: 0.8800\n",
      "25/25 - 0s - loss: 1.0928 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 1.0797 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 1.0668 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 1.0542 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 1.0417 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 1.0295 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 1.0174 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 1.0054 - accuracy: 0.9200\n",
      "25/25 - 0s - loss: 0.9937 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9820 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9705 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9592 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9480 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9371 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9263 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9157 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.9054 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8952 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8852 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8754 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8658 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8563 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8469 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8376 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8285 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8194 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8105 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.8016 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.7929 - accuracy: 0.9600\n",
      "25/25 - 0s - loss: 0.7843 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7757 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7672 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7588 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7505 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7422 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7340 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7259 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7179 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7099 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.7020 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6941 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6863 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6786 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6709 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6632 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6557 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6481 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6406 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6332 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6258 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6185 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6112 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.6040 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5969 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5898 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5828 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5758 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5689 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5621 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5553 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5487 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5421 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5356 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5291 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5228 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5165 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5103 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.5042 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4982 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4922 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4863 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4805 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4748 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4691 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4635 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4579 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4525 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4470 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4417 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4364 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4311 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4259 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4208 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4157 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4107 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4057 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.4008 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3960 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3911 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3864 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3816 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3770 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3723 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3678 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3632 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3587 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3543 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3499 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3455 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3411 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3368 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3326 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3283 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3241 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3200 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 0.3158 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3117 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3077 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.3036 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2997 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2957 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2918 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2879 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2841 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2803 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2766 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2729 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2692 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2656 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2620 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2584 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2549 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2514 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2480 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2379 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2282 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1985 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1957 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1929 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1902 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1875 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1849 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1822 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1796 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1771 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1745 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1720 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1696 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1671 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1647 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1623 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1599 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1576 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1553 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1530 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1508 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1486 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1463 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1442 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1420 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1399 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1378 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1357 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1336 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1315 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1295 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1275 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1255 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1235 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1215 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1196 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1177 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1158 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1140 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1122 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1104 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1086 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1069 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1052 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1035 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1019 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.1003 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0987 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0971 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0956 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0941 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0926 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0911 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0897 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0882 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0868 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0855 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0841 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0828 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0815 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0802 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0789 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0776 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0764 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0752 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0740 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0728 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0717 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0705 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0694 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0683 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0672 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0661 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0651 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0641 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0630 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0620 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0610 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0601 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0591 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0582 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0572 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0563 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0554 - accuracy: 1.0000\n",
      "25/25 - 0s - loss: 0.0545 - accuracy: 1.0000\n",
      "Model accuracy (train data): 100.00%\n",
      "A -> B\n",
      "B -> C\n",
      "C -> D\n",
      "D -> E\n",
      "E -> F\n",
      "F -> G\n",
      "G -> H\n",
      "H -> I\n",
      "I -> J\n",
      "J -> K\n",
      "K -> L\n",
      "L -> M\n",
      "M -> N\n",
      "N -> O\n",
      "O -> P\n",
      "P -> Q\n",
      "Q -> R\n",
      "R -> S\n",
      "S -> T\n",
      "T -> U\n",
      "U -> V\n",
      "V -> W\n",
      "W -> X\n",
      "X -> Y\n",
      "Y -> Z\n",
      "New start: A\n",
      "A -> B\n",
      "A -> C\n",
      "A -> D\n",
      "A -> E\n",
      "A -> F\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # fix random seed for reproducibility\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # define the raw dataset\n",
    "    alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "    # create mapping of characters to integers (0-25) and the reverse\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "    # prepare the dataset of input to output pairs encoded as integers\n",
    "    seq_length = 1\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(alphabet) - seq_length, 1):\n",
    "        seq_in = alphabet[i:i + seq_length]\n",
    "        seq_out = alphabet[i + seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "\n",
    "    # reshape X to be [samples, sequence length, features]\n",
    "    X = np.reshape(dataX, (len(dataX), seq_length, 1))\n",
    "\n",
    "    # normalize\n",
    "    X = X / float(len(alphabet))\n",
    "\n",
    "    # one hot encode the output variable\n",
    "    y = np_utils.to_categorical(dataY)\n",
    "\n",
    "    # create LSTM model\n",
    "    batch_size = 1\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # fit the model\n",
    "    for i in range(300):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    # summarize performance of the model\n",
    "    scores = model.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    model.reset_states()\n",
    "    print(\"Model accuracy (train data): %.2f%%\" % (scores[1] * 100))\n",
    "\n",
    "    # demonstrate some model predictions\n",
    "    seed = [char_to_int[alphabet[0]]]\n",
    "    for i in range(0, len(alphabet) - 1):\n",
    "        x = np.reshape(seed, (1, len(seed), 1))\n",
    "        x = x / float(len(alphabet))\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        print(int_to_char[seed[0]], '->', int_to_char[index])\n",
    "        seed = [index]\n",
    "    model.reset_states()\n",
    "\n",
    "    # demonstrate a random starting point\n",
    "    letter = 'A'\n",
    "    seed = [char_to_int[letter]]\n",
    "    print(\"New start:\", letter)\n",
    "    for i in range(0, 5):\n",
    "        x = np.reshape(seed, (1, len(seed), 1))\n",
    "        x = x / float(len(alphabet))\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        print(int_to_char[seed[0]], '->', int_to_char[index])\n",
    "    model.reset_states()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Alphabet-Prediction_using_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
